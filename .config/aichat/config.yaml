model: local:anthropic/claude-3.7-sonnet
# model: groq:llama-3.3-70b-versatile
temperature: 0
stream: true
save: false
keybindings: vi
editor: nvim
rag_reranker_model: jina:jina-reranker-v2-base-multilingual
rag_embedding_model: jina:jina-embeddings-v2-base-code
rag_top_k: 10
rag_template: |
  Use the following context as your learned knowledge, inside <context></context> XML tags.
  <context>
  __CONTEXT__
  </context>

  When answer to user:
  - If you don't know, just say that you don't know.
  - If you don't know when you are not sure, ask for clarification.
  Avoid mentioning that you obtained the information from the context.
  And answer according to the language of the user's question.

  Given the context information, answer the query.
  Query: __INPUT__
highlight: true
function_calling: true
clients:
  - type: openai-compatible
    name: local
    api_base: http://localhost:8000/v1
    models:
      - name: anthropic/claude-3.7-sonnet
        max_input_tokens: 150000
        supports_vison: false
        supports_function_calling: true
      - name: anthropic/claude-3.7-sonnet:thinking
        max_input_tokens: 150000
        supports_vison: false
        supports_function_calling: true
      - name: deepseek/deepseek-chat
        max_input_tokens: 120000
        supports_vison: false
        supports_function_calling: true
      - name: deepseek/deepseek-r1
        max_input_tokens: 48000
        supports_vison: false
        supports_function_calling: true
      - name: deepseek/deepseek-r1:nitro
        max_input_tokens: 120000
        supports_vison: false
        supports_function_calling: true
      - name: openai/o3-mini
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: false
      - name: openai/o3-mini-high
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: false
  - type: openai-compatible
    name: sambanova
    api_base: https://api.sambanova.ai/v1
    models:
      - name: DeepSeek-R1
        max_input_tokens: 8192
        supports_vision: false
        supports_function_calling: true
      - name: Llama-3.1-Tulu-3-405B
        max_input_tokens: 8192
        supports_vision: false
        supports_function_calling: true
      - name: DeepSeek-R1-Distill-Llama-70B
        max_input_tokens: 8192
        supports_vision: false
        supports_function_calling: true
  - type: openai-compatible
    name: groq
    api_base: https://api.groq.com/openai/v1
    models:
      - name: llama-3.3-70b-versatile
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
      - name: deepseek-r1-distill-llama-70b
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
  - type: openai-compatible
    name: jina
    api_base: https://api.jina.ai/v1
    models:
      - name: jina-embeddings-v2-base-code
        type: embedding
        max_input_tokens: 8192
      - name: jina-reranker-v2-base-multilingual
        type: reranker
