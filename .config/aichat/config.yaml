# model: groq:llama-3.3-70b-versatile
model: sambanova:DeepSeek-V3.1
temperature: 0
stream: false
save: false
keybindings: vi
editor: nvim
rag_reranker_model: jina:jina-reranker-v2-base-multilingual
rag_embedding_model: jina:jina-embeddings-v3
rag_top_k: 10
rag_template: |
  Use the following context as your learned knowledge, inside <context></context> XML tags.
  <context>
  __CONTEXT__
  </context>

  When answer to user:
  - If you don't know, just say that you don't know.
  - If you don't know when you are not sure, ask for clarification.
  Avoid mentioning that you obtained the information from the context.
  And answer according to the language of the user's question.

  Given the context information, answer the query.
  Query: __INPUT__
highlight: true
function_calling: true
document_loaders:
  jina: 'curl -fsSL https://r.jina.ai/$1 -H "Authorization: Bearer $JINA_API_KEY"'
clients:
  - type: openai-compatible
    name: straico
    api_base: https://api.straico.com/v0
    models:
      - name: anthropic/claude-sonnet-4
        max_input_tokens: 128000
        supports_vison: false
        supports_function_calling: true
      - name: openai/gpt-5
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: false
      - name: openai/gpt-5-chat
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: false
  - type: openai-compatible
    name: local
    api_base: http://localhost:8000/v1
    models:
      - name: openai/gpt-5
        max_input_tokens: 256000
        supports_vision: false
        supports_function_calling: false
  - type: openai-compatible
    name: openrouter
    api_base: https://openrouter.ai/api/v1
    models:
      - name: qwen/qwen3-coder:free
        max_input_tokens: 256000
        supports_vision: false
        supports_function_calling: true
      - name: z-ai/glm-4.5-air:free
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
      - name: deepseek/deepseek-chat-v3.1:free
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
      - name: nvidia/nemotron-nano-9b-v2:free
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
      - name: moonshotai/kimi-k2:free
        max_input_tokens: 32000
        supports_vision: false
        supports_function_calling: true
  - type: openai-compatible
    name: sambanova
    api_base: https://api.sambanova.ai/v1
    models:
      - name: DeepSeek-V3.1
        max_input_tokens: 32000
        supports_vision: false
        supports_function_calling: true
  - type: openai-compatible
    name: groq
    api_base: https://api.groq.com/openai/v1
    models:
      - name: llama-3.3-70b-versatile
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
      - name: groq/compound
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
      - name: moonshotai/kimi-k2-instruct-0905
        max_input_tokens: 128000
        supports_vision: false
        supports_function_calling: true
  - type: openai-compatible
    name: jina
    api_base: https://api.jina.ai/v1
    models:
      - name: jina-embeddings-v2-base-code
        type: embedding
        max_input_tokens: 8192
      - name: jina-embeddings-v3
        type: embedding
        max_input_tokens: 8192
      - name: jina-reranker-v2-base-multilingual
        type: reranker
